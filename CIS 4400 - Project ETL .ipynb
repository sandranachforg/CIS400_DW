{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETL - Data Transformation\n",
    "\n",
    "05/03/2021"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sandra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sandra/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy as tw #to \n",
    "import re\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "from preprocessor.api import clean, tokenize, parse\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import datetime as dt\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "from textblob import TextBlob\n",
    "\n",
    "import requests \n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  We are interested in the sentiment of the following companies :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Netflix (hashtag: netflix) \\\n",
    "b) Coca Cola (hashtag: CocaCola) \\\n",
    "c) Tesla (hashtag: Tesla)\\\n",
    "d) Nike (hashtag: Nike) \\\n",
    "e) Apple (hashtag: Apple) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create a function to extract data from Alpha Vantage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-2-49d9030a47a9>:13: FutureWarning: pandas.io.json.json_normalize is deprecated, use pandas.json_normalize instead\n",
      "  df = json_normalize(data)   #transforms the data into a dataframe\n"
     ]
    }
   ],
   "source": [
    "#Authors: Hussaan, Sahil, Sandra\n",
    "\n",
    "def get_company_data(symbol,key):\n",
    "    \n",
    "    key = key\n",
    "    url= \"https://www.alphavantage.co/query?\"\n",
    "    parameters = {\n",
    "            \"function\": \"OVERVIEW\",\n",
    "            \"symbol\":symbol,\n",
    "            \"apikey\":key,\n",
    "            \n",
    "    }\n",
    "    r= requests.get(url,params=parameters)\n",
    "    data = r.json()\n",
    "    df = json_normalize(data)   #transforms the data into a dataframe\n",
    "    df  = df[[\"Name\", \"Sector\", \"Industry\"]]   #returns only select columns\n",
    "    \n",
    "    return df\n",
    "\n",
    "dfNFLX=get_company_data(\"NFLX\",\"5LD0SCCP1XWGHFU4\") # apply function to get company data\n",
    "dfTSLA=get_company_data(\"TSLA\",\"5LD0SCCP1XWGHFU4\")\n",
    "dfKO=get_company_data(\"KO\",\"5LD0SCCP1XWGHFU4\")\n",
    "dfSBUX=get_company_data(\"SBUX\",\"5LD0SCCP1XWGHFU4\")\n",
    "dfNKE=get_company_data(\"NKE\",\"5LD0SCCP1XWGHFU4\")\n",
    "\n",
    "company_dim = pd.concat([dfNFLX,dfTSLA, dfKO, dfSBUX, dfNKE], axis=0, ignore_index=True) #combine all dataframes into a single one\n",
    "company_dim[\"company_id\"]=company_dim.index+1; # create a company_id for each company\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create a dataframe containing document_id and source\n",
    "We only have two sources for this project, the Twitter API and News API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   document_id    source\n",
      "0            1   Twitter\n",
      "1            2  News API\n"
     ]
    }
   ],
   "source": [
    "#Author: Sandra\n",
    "\n",
    "d= {'document_id': [1, 2], \"source\": [\"Twitter\", \"News API\"]}\n",
    "document_dim = pd.DataFrame(data=d)\n",
    "\n",
    "print (document_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Authorize Account for Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authorize?oauth_token=-8y7sQAAAAABNQviAAABeS2Q_6w\n",
      "What's the pin value? 5608340\n"
     ]
    }
   ],
   "source": [
    "#Author: Sandra\n",
    "\n",
    "#To get consumer_key, consumer_secret, access_token, access_token_secret you have to apply for Twitter developer account\n",
    "\n",
    "consumer_key= ''  \n",
    "consumer_secret= ''\n",
    "access_token= \"\"\n",
    "access_token_secret= ''\n",
    "callback_url = 'oob'\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret, callback_url) #creating an OAuthHandler instance\n",
    "redirect_url= auth.get_authorization_url()\n",
    "\n",
    "print (redirect_url)\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "user_pin_input = input (\"What's the pin value? \")\n",
    "api = tw.API (auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create a function to extract data from Twitter API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes 2 parameters and helps us extract the data from twitter\n",
    "# The \"hashtag\" is the company name we are analyzing\n",
    "# The \"company_id\" is the id we assigned to that particular company in the company dimensions\n",
    "\n",
    "def get_tweets(hashtag, company_id):\n",
    "    \n",
    "    number_of_tweets = 100\n",
    "    tweets = []\n",
    "    likes= []\n",
    "    time= []\n",
    "    user = []\n",
    "    author = []\n",
    "    retweet=[]\n",
    "    \n",
    "    # q = pass the hashtags\n",
    "    \n",
    "    for i in tw.Cursor(api.search, \n",
    "                       q= hashtag, \n",
    "                       tweet_mode= 'extended', \n",
    "                       lang= \"en\",\n",
    "                       since= date_since,\n",
    "                       until = date_until).items(number_of_tweets):\n",
    "        tweets.append(i.full_text)\n",
    "        likes.append(i.favorite_count)\n",
    "        time.append(i.created_at)\n",
    "        retweet.append(i.retweet_count) \n",
    "      \n",
    "        \n",
    "    df= pd.DataFrame({'tweets': tweets, 'likes': likes, 'timestamp': time, 'retweet': retweet})\n",
    "    \n",
    "    df[\"document_id\"] = 1\n",
    "    df[\"company_id\"] = company_id\n",
    "    \n",
    "    df= df[[\"company_id\", \"timestamp\", \"document_id\", \"tweets\", \"retweet\", \"likes\"]]\n",
    "    \n",
    "    df.rename(columns = {\"timestamp\": \"time_id\", \"tweets\": \"original_description\", \n",
    "                        \"retweet\": \"retweet_count\", \"likes\": \"like_count\"}, inplace= True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Create function to get data from News API - can also specify the publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Mohamed Abouregila\n",
    "get_headlines()\n",
    " this function takes company, fromDate, and to date in form of  \"yyyy-mm-dd\", and returns a dataframe of all \n",
    " headlines posted about this company in the specified period\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'''Modified: add additional argument: company_id to differentiate from each other - Sandra Nachforg'''\n",
    "\n",
    "def get_headlines(company_id, company,fromDate,toDate,key):\n",
    "    \n",
    "    url= \"http://newsapi.org/v2/everything?\"\n",
    "    parameters = {\n",
    "            \"qInTitle\": company,\n",
    "            \"language\":\"en\",\n",
    "            \"from\":fromDate,\n",
    "            \"to\":toDate,\n",
    "            \"apiKey\":key,\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url,params=parameters)\n",
    "\n",
    "    df = response.json()\n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    df = pd.concat([df.drop(['articles'], axis=1), df['articles'].apply(pd.Series)], axis=1)\n",
    "    df [[\"Drop\",\"source\"]] = df.source.apply(pd.Series)\n",
    "    df [\"company_id\"]  = company_id\n",
    "    df [\"document_id\"] = 2\n",
    "    df [\"retweet_count\"] = \"\"\n",
    "    df [\"like_count\"] = \"\"\n",
    "    \n",
    "    df = df [[\"company_id\", \"publishedAt\", \"document_id\", \"title\", \"retweet_count\", \"like_count\"]]\n",
    "    \n",
    "    \n",
    "    df [\"publishedAt\"] = pd.to_datetime(df.publishedAt).dt.tz_localize(None)\n",
    "    \n",
    "    df.rename(columns = {\"publishedAt\": \"time_id\", \"title\": \"original_description\"}, inplace = True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Apply function to extract tweets from Twitter\n",
    "Apply the \"get_tweets()\"-  function\n",
    "\n",
    "This function takes 2 arguments: hashtag (e.g. netflix), company_id (based on copmany dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_twitter = get_tweets(\"netflix\", 1)    #netflix, 1 - company_id, 1- document_id \n",
    "tesla_twitter = get_tweets(\"tsla\", 2) \n",
    "cocacola_twitter = get_tweets(\"cocacola\", 3)\n",
    "starbucks_twitter = get_tweets(\"starbucks\", 4)\n",
    "nike_twitter = get_tweets(\"nike\", 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Get headlines for the companies - Apply the get_headlines () - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_news = get_headlines (1, \"netflix\",'2021-04-21','2021-04-22', \"\" )\n",
    "tesla_news = get_headlines (2, \"tesla\", '2021-04-21','2021-04-22', \"\" )\n",
    "#cocacola_news = get_headlines (3, \"cocacola\", '2021-04-21','2021-04-22', \"\" ) #\n",
    "starbucks_news = get_headlines (4, \"starbucks\", '2021-04-21','2021-04-22', \"\" )\n",
    "nike_news = get_headlines (5, \"nike\", '2021-04-21','2021-04-22', \"\" ) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Concat all dataframes containing tweets and newspaper headlines \n",
    "(stack on top of each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = pd.concat([netflix_twitter,tesla_twitter, cocacola_twitter, starbucks_twitter, nike_twitter,\n",
    "                        netflix_news, tesla_news, starbucks_news, nike_news], axis=0)   #stacks each dataframe on top of each other\n",
    "\n",
    "fact_table.to_csv(\"fact_table.csv\")  #saves fact_table --> in case we want to save a copy to our hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>original_description</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-01 20:09:34</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @dooleyanthony: If your sat there and there...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-01 20:09:34</td>\n",
       "      <td>1</td>\n",
       "      <td>Come Check Out CloudGamer201 TV Here: https://...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-01 20:09:34</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @KEEMSTAR: Before we had\\nCable tv with all...</td>\n",
       "      <td>149</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-01 20:09:33</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @Kumong_bato: Hey @netflix , and @nowthisne...</td>\n",
       "      <td>1983</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-05-01 20:09:32</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @NetflixSA: Here's your first look at #Mons...</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id             time_id  document_id  \\\n",
       "0           1 2021-05-01 20:09:34            1   \n",
       "1           1 2021-05-01 20:09:34            1   \n",
       "2           1 2021-05-01 20:09:34            1   \n",
       "3           1 2021-05-01 20:09:33            1   \n",
       "4           1 2021-05-01 20:09:32            1   \n",
       "\n",
       "                                original_description retweet_count like_count  \n",
       "0  RT @dooleyanthony: If your sat there and there...             4          0  \n",
       "1  Come Check Out CloudGamer201 TV Here: https://...             0          0  \n",
       "2  RT @KEEMSTAR: Before we had\\nCable tv with all...           149          0  \n",
       "3  RT @Kumong_bato: Hey @netflix , and @nowthisne...          1983          0  \n",
       "4  RT @NetflixSA: Here's your first look at #Mons...            67          0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Create function to clean original_descriptions \n",
    "To get it ready for sentiment analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to do this to do sentiment analysis on the headlines/tweets later\n",
    "\n",
    "#Author: Sandra \n",
    "\n",
    "def cleanup_description(s):\n",
    "    text = s.lower().split()       # makes all characters lower case\n",
    "    text = list(filter(lambda x: \"http\" not in x, text))        # removes http\n",
    "    text = list(filter(lambda x: not x.startswith(\"@\"), text))   #removes the @\n",
    "    text = list(map(lambda x: emoji.demojize(x, delimiters=(\"\", \",\")).replace(\"_\", \" \"), text))  # replaces emojis with word\n",
    "    text = list(map(lambda x: re.sub(\"[^a-zA-Z ]+\", \"\", x), text)) \n",
    "    #only keeps letter from a-z and A-Z\n",
    "    #text = [word for word in text if not word in stopwords.words()]     #removes stop words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = list(map(lambda x: lemmatizer.lemmatize(x), text))     #lemmatizes the text\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. Create a function that calculates the sentiment score for each clean_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Sandra\n",
    "\n",
    "def get_sentiment_score(df):\n",
    "    \n",
    "    df[\"cleaned_description\"] =  df[\"original_description\"].apply(lambda x: cleanup_description(x))\n",
    "    df[[\"polarity\", \"subjectivity\"]] = df[\"cleaned_description\"].apply(lambda x: pd.Series(TextBlob(x).sentiment))\n",
    "\n",
    "    for index, row in df[\"cleaned_description\"].iteritems():\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    \n",
    "        neg = score[\"neg\"]\n",
    "        neu = score[\"neu\"]\n",
    "        pos = score[\"pos\"]\n",
    "        comp = score[\"compound\"]\n",
    "    \n",
    "        if neg > pos:\n",
    "            df.loc[index, \"sentiment\"] = \"negative\"\n",
    "        elif pos > neg:\n",
    "            df.loc[index, \"sentiment\"] = \"positive\"\n",
    "        else:\n",
    "            df.loc[index, \"sentiment\"] = \"neutral\"\n",
    "    \n",
    "    df.rename(columns = {\"timestamp\": \"time_id\", \"tweets\": \"original_description\", \"cleaned_tweets\":\"cleaned_description\", \n",
    "                        \"retweet\": \"retweet_count\", \"likes\": \"like_count\"}, inplace = True)\n",
    "    \n",
    "    df = df[[\"company_id\", \"time_id\", \"document_id\", \"original_description\",\"cleaned_description\", \"retweet_count\", \n",
    "            \"like_count\", \"polarity\", \"subjectivity\", \"sentiment\"]]\n",
    "    \n",
    "    \n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. After we have our finished dataframe, we can apply  the \"get_sentiment_score\"- function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = get_sentiment_score(fact_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 13. Lastly - we create time dimension by getting all unique timestamps from fact table and then transform it  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Author: Sandra\n",
    "\n",
    "def get_time_dim(df):\n",
    "    df_time= df[[\"time_id\"]]\n",
    "    df_time['date_time'] = pd.to_datetime(df['time_id']).dt.time\n",
    "    df_time['day']= pd.to_datetime(df['time_id']).dt.day\n",
    "    df_time['month']= pd.to_datetime(df['time_id']).dt.month\n",
    "    df_time['year']= pd.to_datetime(df['time_id']).dt.year\n",
    "    \n",
    "    df_time.drop_duplicates(inplace = True)\n",
    "    \n",
    "    return df_time\n",
    "\n",
    "## timestamp is the primary key here in SQL\n",
    "## In fact table it is part of the primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-12-96a2bbe45713>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['date_time'] = pd.to_datetime(df['time_id']).dt.time\n",
      "<ipython-input-12-96a2bbe45713>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['day']= pd.to_datetime(df['time_id']).dt.day\n",
      "<ipython-input-12-96a2bbe45713>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['month']= pd.to_datetime(df['time_id']).dt.month\n",
      "<ipython-input-12-96a2bbe45713>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['year']= pd.to_datetime(df['time_id']).dt.year\n",
      "<ipython-input-12-96a2bbe45713>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time.drop_duplicates(inplace = True)\n"
     ]
    }
   ],
   "source": [
    "df_time = get_time_dim(fact_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>date_time</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-05-01 20:09:34</td>\n",
       "      <td>20:09:34</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-05-01 20:09:33</td>\n",
       "      <td>20:09:33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-05-01 20:09:32</td>\n",
       "      <td>20:09:32</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2021-05-01 20:09:27</td>\n",
       "      <td>20:09:27</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-05-01 20:09:26</td>\n",
       "      <td>20:09:26</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-04-22 15:23:23</td>\n",
       "      <td>15:23:23</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-04-22 04:44:03</td>\n",
       "      <td>04:44:03</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2021-04-21 08:49:46</td>\n",
       "      <td>08:49:46</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-04-22 11:23:43</td>\n",
       "      <td>11:23:43</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-04-21 19:19:16</td>\n",
       "      <td>19:19:16</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>425 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time_id date_time  day  month  year\n",
       "0  2021-05-01 20:09:34  20:09:34    1      5  2021\n",
       "3  2021-05-01 20:09:33  20:09:33    1      5  2021\n",
       "4  2021-05-01 20:09:32  20:09:32    1      5  2021\n",
       "5  2021-05-01 20:09:27  20:09:27    1      5  2021\n",
       "6  2021-05-01 20:09:26  20:09:26    1      5  2021\n",
       "..                 ...       ...  ...    ...   ...\n",
       "15 2021-04-22 15:23:23  15:23:23   22      4  2021\n",
       "16 2021-04-22 04:44:03  04:44:03   22      4  2021\n",
       "17 2021-04-21 08:49:46  08:49:46   21      4  2021\n",
       "18 2021-04-22 11:23:43  11:23:43   22      4  2021\n",
       "19 2021-04-21 19:19:16  19:19:16   21      4  2021\n",
       "\n",
       "[425 rows x 5 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14. When data is ready, we load it into the MySQL Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymysql in ./opt/anaconda3/lib/python3.8/site-packages (1.0.2)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x7fce5f213460>\n"
     ]
    }
   ],
   "source": [
    "#create a connection to local database\n",
    "\n",
    "connection = pymysql.connect(host= '127.0.0.1',\n",
    "                            user = 'root', \n",
    "                            password = '',\n",
    "                            db= 'pr_sentiment',\n",
    "                            cursorclass = pymysql.cursors.DictCursor)\n",
    "\n",
    "print (connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor= connection.cursor() #create a cursor element\n",
    "connection.commit()   #commit the connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 14.1 Import data into the dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we load data from our company_dim (Dataframe) into our database table that we already created\n",
    "\n",
    "for i,row in company_dim.iterrows():\n",
    "    \n",
    "    cursor.execute(\"INSERT INTO company_dim (company_id, company_name, sector, industry) values (%s, %s, %s, %s)\", [row [\"company_id\"],row[\"Name\"], row[\"Sector\"], row [\"Industry\"]]);\n",
    "\n",
    "connection.commit()\n",
    "\n",
    "#load data from document_dim to table in SQL database\n",
    "for i, row in document_dim.iterrows():\n",
    "    cursor.execute(\"INSERT INTO document_dim (document_id, source) values (%s, %s)\", [row[\"document_id\"], row[\"source\"]]);\n",
    "    \n",
    "connection.commit()\n",
    "\n",
    "#Load data from df_time to table in database\n",
    "\n",
    "for i, row in df_time.iterrows():\n",
    "    cursor.execute(\"INSERT INTO time_dim (time_id, date_time, day, month, year) values (%s, %s, %s, %s, %s)\", [row[\"time_id\"], row [\"date_time\"], row[\"day\"], row[\"month\"], row[\"year\"]]);\n",
    "    \n",
    "connection.commit()\n",
    "\n",
    "#load data from fact_table into the fact table in SQL\n",
    "\n",
    "for i, row in fact_table.iterrows():\n",
    "    cursor.execute (\"INSERT INTO fact_table (company_id, time_id, document_id, original_description, cleaned_description, retweet_count, like_count, polarity, subjectivity, sentiment) values (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s)\", [row[\"company_id\"], row[\"time_id\"], row[\"document_id\"], row[\"original_description\"], row [\"cleaned_description\"], row [\"retweet_count\"], row[\"like_count\"], row[\"polarity\"], row[\"subjectivity\"], row[\"sentiment\"]]);\n",
    "\n",
    "connection.commit()  #commit changes\n",
    "connection.close() # close connection"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
