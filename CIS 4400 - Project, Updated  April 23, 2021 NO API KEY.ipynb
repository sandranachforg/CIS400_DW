{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ETL - Data Transformation\n",
    "\n",
    "@by Sandra Nachforg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sandra/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/sandra/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/sandra/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import tweepy as tw\n",
    "import re\n",
    "import pandas as pd\n",
    "import preprocessor as p\n",
    "from preprocessor.api import clean, tokenize, parse\n",
    "import re, string, unicodedata\n",
    "import nltk\n",
    "import datetime as dt\n",
    "import emoji\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "from textblob import TextBlob\n",
    "\n",
    "import requests \n",
    "import pandas as pd\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  We are interested in the sentiment of the following companies :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Netflix (hashtag: netflix) \\\n",
    "b) Coca Cola (hashtag: CocaCola) \\\n",
    "c) Tesla (hashtag: Tesla)\\\n",
    "d) Nike (hashtag: Nike) \\\n",
    "e) Apple (hashtag: Apple) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Get data from Alpha Vantage (API that has company information)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "key = \"\"\n",
    "URL= \"https://www.alphavantage.co/query?function=OVERVIEW&symbol=AAPL&apikey=key\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_company_data(company,key):\n",
    "    \n",
    "    key = key\n",
    "    URL= \"https://www.alphavantage.co/query?function=OVERVIEW\"\n",
    "    r= requests.get(url= URL)\n",
    "    data = r.json()\n",
    "    df = json_normalize(data)   #transforms the data into a dataframe\n",
    "    df  = df[[\"Name\", \"Sector\", \"Industry\"]]   #returns only select columns\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Authorize Account for Twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.twitter.com/oauth/authorize?oauth_token=nrwmkAAAAAABNQviAAABeP9Ar0U\n",
      "What's the pin value? 7352082\n"
     ]
    }
   ],
   "source": [
    "consumer_key= ''\n",
    "consumer_secret= ''\n",
    "access_token= \"\"\n",
    "access_token_secret= ''\n",
    "callback_url = 'oob'\n",
    "\n",
    "auth = tw.OAuthHandler(consumer_key, consumer_secret, callback_url)\n",
    "redirect_url= auth.get_authorization_url()\n",
    "\n",
    "print (redirect_url)\n",
    "\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tw.API(auth, wait_on_rate_limit=True)\n",
    "\n",
    "user_pin_input = input (\"What's the pin value? \")\n",
    "api = tw.API (auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Get function to get data from Twitter API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function takes 3 parameters and helps us extract the data from twitter\n",
    "# The \"hashtag\" is the company name we are analyzing\n",
    "# The \"company_id\" is the id we assigned to that particular company in the company dimensions\n",
    "# The \"document_id\" is the id we assigned to source (Twitter  - 1, Forbes - 2 etc.) \n",
    "\n",
    "def get_tweets(hashtag, company_id, document_id):\n",
    "    \n",
    "    number_of_tweets = 100\n",
    "    tweets = []\n",
    "    likes= []\n",
    "    time= []\n",
    "    user = []\n",
    "    author = []\n",
    "    retweet=[]\n",
    "    \n",
    "    # q = pass the hashtags\n",
    "    \n",
    "    for i in tw.Cursor(api.search, q= hashtag, tweet_mode= 'extended', lang= \"en\").items(number_of_tweets):\n",
    "        tweets.append(i.full_text)\n",
    "        likes.append(i.favorite_count)\n",
    "        time.append(i.created_at)\n",
    "        retweet.append(i.retweet_count) \n",
    "      \n",
    "        \n",
    "    df= pd.DataFrame({'tweets': tweets, 'likes': likes, 'timestamp': time, 'retweet': retweet})\n",
    "    \n",
    "    df[\"document_id\"] = document_id\n",
    "    df[\"company_id\"] = company_id\n",
    "    \n",
    "    df= df[[\"company_id\", \"timestamp\", \"document_id\", \"tweets\", \"retweet\", \"likes\"]]\n",
    "    \n",
    "    df.rename(columns = {\"timestamp\": \"time_id\", \"tweets\": \"original_description\", \n",
    "                        \"retweet\": \"retweet_count\", \"likes\": \"like_count\"}, inplace= True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Create function to get data from News API - can also specify the publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@author: Mohamed Abouregila\n",
    "get_headlines()\n",
    " this function takes company, fromDate, and to date in form of  \"yyyy-mm-dd\", and returns a dataframe of all \n",
    " headlines posted about this company in the specified period\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "'''Modified: add additional argument: company_id to differentiate from each other - Sandra Nachforg'''\n",
    "\n",
    "def get_headlines(company_id, company,fromDate,toDate,key):\n",
    "    \n",
    "    url= \"http://newsapi.org/v2/everything?\"\n",
    "    parameters = {\n",
    "            \"qInTitle\": company,\n",
    "            \"language\":\"en\",\n",
    "            \"from\":fromDate,\n",
    "            \"to\":toDate,\n",
    "            \"apiKey\":key,\n",
    "    }\n",
    "    \n",
    "    response = requests.get(url,params=parameters)\n",
    "\n",
    "    df = response.json()\n",
    "    df = pd.DataFrame.from_dict(df)\n",
    "    df = pd.concat([df.drop(['articles'], axis=1), df['articles'].apply(pd.Series)], axis=1)\n",
    "    df [[\"Drop\",\"source\"]] = df.source.apply(pd.Series)\n",
    "    df [\"company_id\"]  = company_id\n",
    "    df [\"document_id\"] = 2\n",
    "    df [\"retweet_count\"] = \"\"\n",
    "    df [\"like_count\"] = \"\"\n",
    "    \n",
    "    df = df [[\"company_id\", \"publishedAt\", \"document_id\", \"title\", \"retweet_count\", \"like_count\"]]\n",
    "    \n",
    "    \n",
    "    df [\"publishedAt\"] = pd.to_datetime(df_news.publishedAt).dt.tz_localize(None)\n",
    "    \n",
    "    df.rename(columns = {\"publishedAt\": \"time_id\", \"title\": \"original_description\"}, inplace = True)\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Get tweets for the companies- Apply the \"get_tweets()\"-  function\n",
    "\n",
    "This function takes three arguments: hashtag (e.g. netflix), company_id (based on copmany dimension), document_id (based on document dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_twitter = get_tweets(\"netflix\", 1,1)    #netflix, 1 - company_id, 1- document_id \n",
    "tesla_twitter = get_tweets(\"tsla\", 2, 1) \n",
    "cocacola_twitter = get_tweets(\"cocacola\", 3,1)\n",
    "starbucks_twitter = get_tweets(\"starbucks\", 4, 1 )\n",
    "nike_twitter = get_tweets(\"nike\", 5, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Get headlines for the companies - Apply the get_headlines () - function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix_news = get_headlines (1, \"netflix\",'2021-04-21','2021-04-22', \"\" )\n",
    "tesla_news = get_headlines (2, \"tesla\", '2021-04-21','2021-04-22', \"\")\n",
    "#cocacola_news = get_headlines (3, \"cocacola\", '2021-04-21','2021-04-22', \"\")\n",
    "starbucks_news = get_headlines (4, \"starbucks\", '2021-04-21','2021-04-22', \"\")\n",
    "nike_news = get_headlines (5, \"nike\", '2021-04-21','2021-04-22', \"\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Concat all dataframes (stack on top of each other)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_table = pd.concat([netflix_twitter,tesla_twitter, cocacola_twitter, starbucks_twitter, nike_twitter,\n",
    "                        netflix_news, tesla_news, starbucks_news, nike_news], axis=0)   #stacks each dataframe on top of each other\n",
    "\n",
    "fact_table.to_csv(\"fact_table.csv\")  #saves fact_table --> in case we want to save a copy to our hard drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>original_description</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @netflix: When you know, you know. \\n\\n(📺: ...</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>HAPPY SHADOW &amp;amp; BONE NETFLIX RELEASE DAY! \\...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @PlsSister: Who will win?\\n@netflix @Netfli...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @FilmCompanion: Now that #WildDog is stream...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:46</td>\n",
       "      <td>1</td>\n",
       "      <td>@leslisa5 @killerm0odz @netflix You crossed a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   company_id             time_id  document_id  \\\n",
       "0           1 2021-04-23 15:02:47            1   \n",
       "1           1 2021-04-23 15:02:47            1   \n",
       "2           1 2021-04-23 15:02:47            1   \n",
       "3           1 2021-04-23 15:02:47            1   \n",
       "4           1 2021-04-23 15:02:46            1   \n",
       "\n",
       "                                original_description retweet_count like_count  \n",
       "0  RT @netflix: When you know, you know. \\n\\n(📺: ...           337          0  \n",
       "1  HAPPY SHADOW &amp; BONE NETFLIX RELEASE DAY! \\...             0          0  \n",
       "2  RT @PlsSister: Who will win?\\n@netflix @Netfli...             2          0  \n",
       "3  RT @FilmCompanion: Now that #WildDog is stream...             2          0  \n",
       "4  @leslisa5 @killerm0odz @netflix You crossed a ...             0          0  "
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fact_table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 9. Create function to clean original_descriptions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to do this to do sentiment analysis on the headlines/tweets later\n",
    "\n",
    "def cleanup_description(s):\n",
    "    text = s.lower().split()       # makes all characters lower case\n",
    "    text = list(filter(lambda x: \"http\" not in x, text))        # removes http\n",
    "    text = list(filter(lambda x: not x.startswith(\"@\"), text))   #removes the @\n",
    "    text = list(map(lambda x: emoji.demojize(x, delimiters=(\"\", \",\")).replace(\"_\", \" \"), text))  # replaces emojis with word\n",
    "    text = list(map(lambda x: re.sub(\"[^a-zA-Z ]+\", \"\", x), text)) \n",
    "    #only keeps letter from a-z and A-Z\n",
    "    #text = [word for word in text if not word in stopwords.words()]     #removes stop words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text = list(map(lambda x: lemmatizer.lemmatize(x), text))     #lemmatizes the text\n",
    "    \n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 10. Create a function that calculates the sentiment score for each clean_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score(df):\n",
    "    \n",
    "    df[\"cleaned_description\"] =  df[\"original_description\"].apply(lambda x: cleanup_description(x))\n",
    "    df[[\"polarity\", \"subjectivity\"]] = df[\"cleaned_description\"].apply(lambda x: pd.Series(TextBlob(x).sentiment))\n",
    "\n",
    "    for index, row in df[\"cleaned_description\"].iteritems():\n",
    "        score = SentimentIntensityAnalyzer().polarity_scores(row)\n",
    "    \n",
    "        neg = score[\"neg\"]\n",
    "        neu = score[\"neu\"]\n",
    "        pos = score[\"pos\"]\n",
    "        comp = score[\"compound\"]\n",
    "    \n",
    "        if neg > pos:\n",
    "            df.loc[index, \"sentiment\"] = \"negative\"\n",
    "        elif pos > neg:\n",
    "            df.loc[index, \"sentiment\"] = \"positive\"\n",
    "        else:\n",
    "            df.loc[index, \"sentiment\"] = \"neutral\"\n",
    "    \n",
    "    df.rename(columns = {\"timestamp\": \"time_id\", \"tweets\": \"original_description\", \"cleaned_tweets\":\"cleaned_description\", \n",
    "                        \"retweet\": \"retweet_count\", \"likes\": \"like_count\"}, inplace = True)\n",
    "    \n",
    "    df = df[[\"company_id\", \"time_id\", \"document_id\", \"original_description\",\"cleaned_description\", \"retweet_count\", \n",
    "            \"like_count\", \"polarity\", \"subjectivity\", \"sentiment\"]]\n",
    "    \n",
    "    \n",
    "            \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 11. After we have our finished dataframe, we can apply  the \"get_sentiment_score\"- function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>company_id</th>\n",
       "      <th>time_id</th>\n",
       "      <th>document_id</th>\n",
       "      <th>original_description</th>\n",
       "      <th>cleaned_description</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>like_count</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @netflix: When you know, you know. \\n\\n(📺: ...</td>\n",
       "      <td>rt when you know you know television the circle</td>\n",
       "      <td>337</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>HAPPY SHADOW &amp;amp; BONE NETFLIX RELEASE DAY! \\...</td>\n",
       "      <td>happy shadow amp bone netflix release day dont...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4125</td>\n",
       "      <td>0.625</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @PlsSister: Who will win?\\n@netflix @Netfli...</td>\n",
       "      <td>rt who will win please give u the warriornunbl...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.400</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>1</td>\n",
       "      <td>RT @FilmCompanion: Now that #WildDog is stream...</td>\n",
       "      <td>rt now that wilddog is streaming on netflix sh...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.100</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-04-23 15:02:46</td>\n",
       "      <td>1</td>\n",
       "      <td>@leslisa5 @killerm0odz @netflix You crossed a ...</td>\n",
       "      <td>you crossed a line</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-22 23:55:45</td>\n",
       "      <td>2</td>\n",
       "      <td>This Nike Air Max 90 \"Cork\" Slide is Perfect f...</td>\n",
       "      <td>this nike air max  cork slide is perfect for l...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-22 23:56:03</td>\n",
       "      <td>2</td>\n",
       "      <td>Erik Arteaga Announces Vyzer LA Sponsorship Sk...</td>\n",
       "      <td>erik arteaga announces vyzer la sponsorship sk...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21 11:27:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Take an Official Look At the Nike SB Dunk High...</td>\n",
       "      <td>take an official look at the nike sb dunk high...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.1600</td>\n",
       "      <td>0.540</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21 22:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Nike &amp; Urbanstar Team Up With The Silhouettes ...</td>\n",
       "      <td>nike  urbanstar team up with the silhouette pr...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21 18:27:00</td>\n",
       "      <td>2</td>\n",
       "      <td>Nike Refurbished Gets More Mileage Out Of Used...</td>\n",
       "      <td>nike refurbished get more mileage out of used ...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>0.5000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>571 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    company_id             time_id  document_id  \\\n",
       "0            1 2021-04-23 15:02:47            1   \n",
       "1            1 2021-04-23 15:02:47            1   \n",
       "2            1 2021-04-23 15:02:47            1   \n",
       "3            1 2021-04-23 15:02:47            1   \n",
       "4            1 2021-04-23 15:02:46            1   \n",
       "..         ...                 ...          ...   \n",
       "15           5 2021-04-22 23:55:45            2   \n",
       "16           5 2021-04-22 23:56:03            2   \n",
       "17           5 2021-04-21 11:27:00            2   \n",
       "18           5 2021-04-21 22:00:00            2   \n",
       "19           5 2021-04-21 18:27:00            2   \n",
       "\n",
       "                                 original_description  \\\n",
       "0   RT @netflix: When you know, you know. \\n\\n(📺: ...   \n",
       "1   HAPPY SHADOW &amp; BONE NETFLIX RELEASE DAY! \\...   \n",
       "2   RT @PlsSister: Who will win?\\n@netflix @Netfli...   \n",
       "3   RT @FilmCompanion: Now that #WildDog is stream...   \n",
       "4   @leslisa5 @killerm0odz @netflix You crossed a ...   \n",
       "..                                                ...   \n",
       "15  This Nike Air Max 90 \"Cork\" Slide is Perfect f...   \n",
       "16  Erik Arteaga Announces Vyzer LA Sponsorship Sk...   \n",
       "17  Take an Official Look At the Nike SB Dunk High...   \n",
       "18  Nike & Urbanstar Team Up With The Silhouettes ...   \n",
       "19  Nike Refurbished Gets More Mileage Out Of Used...   \n",
       "\n",
       "                                  cleaned_description retweet_count  \\\n",
       "0     rt when you know you know television the circle           337   \n",
       "1   happy shadow amp bone netflix release day dont...             0   \n",
       "2   rt who will win please give u the warriornunbl...             2   \n",
       "3   rt now that wilddog is streaming on netflix sh...             2   \n",
       "4                                  you crossed a line             0   \n",
       "..                                                ...           ...   \n",
       "15  this nike air max  cork slide is perfect for l...                 \n",
       "16  erik arteaga announces vyzer la sponsorship sk...                 \n",
       "17  take an official look at the nike sb dunk high...                 \n",
       "18  nike  urbanstar team up with the silhouette pr...                 \n",
       "19  nike refurbished get more mileage out of used ...                 \n",
       "\n",
       "   like_count  polarity  subjectivity sentiment  \n",
       "0           0    0.0000         0.000   neutral  \n",
       "1           0    0.4125         0.625  positive  \n",
       "2           0    0.8000         0.400  negative  \n",
       "3           0    0.0000         0.100   neutral  \n",
       "4           0    0.0000         0.000  positive  \n",
       "..        ...       ...           ...       ...  \n",
       "15               1.0000         1.000  positive  \n",
       "16               0.0000         0.000   neutral  \n",
       "17               0.1600         0.540   neutral  \n",
       "18               0.0000         0.000   neutral  \n",
       "19               0.5000         0.500   neutral  \n",
       "\n",
       "[571 rows x 10 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_sentiment_score(fact_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 12. Lastly - we create time dimension by getting all unique timestamps from fact table and then transform it  \n",
    "@ by Sandra Nachforg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time_dim(df):\n",
    "    df_time= df[[\"time_id\"]]\n",
    "    df_time['Time'] = pd.to_datetime(df['time_id']).dt.time\n",
    "    df_time['Day']= pd.to_datetime(df['time_id']).dt.day\n",
    "    df_time['Month']= pd.to_datetime(df['time_id']).dt.month\n",
    "    df_time['Year']= pd.to_datetime(df['time_id']).dt.year\n",
    "    \n",
    "    df_time.drop_duplicates(inplace = True)\n",
    "    \n",
    "    return df_time\n",
    "\n",
    "## timestamp is the primary key here in SQL\n",
    "## In fact table it is part of the primary key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-154-a8e35094c473>:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['Time'] = pd.to_datetime(df['time_id']).dt.time\n",
      "<ipython-input-154-a8e35094c473>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['Day']= pd.to_datetime(df['time_id']).dt.day\n",
      "<ipython-input-154-a8e35094c473>:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['Month']= pd.to_datetime(df['time_id']).dt.month\n",
      "<ipython-input-154-a8e35094c473>:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time['Year']= pd.to_datetime(df['time_id']).dt.year\n",
      "<ipython-input-154-a8e35094c473>:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_time.drop_duplicates(inplace = True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>Time</th>\n",
       "      <th>Day</th>\n",
       "      <th>Month</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-04-23 15:02:47</td>\n",
       "      <td>15:02:47</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021-04-23 15:02:46</td>\n",
       "      <td>15:02:46</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021-04-23 15:02:45</td>\n",
       "      <td>15:02:45</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2021-04-23 15:02:44</td>\n",
       "      <td>15:02:44</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2021-04-23 15:02:43</td>\n",
       "      <td>15:02:43</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2021-04-22 14:18:31</td>\n",
       "      <td>14:18:31</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021-04-22 23:55:45</td>\n",
       "      <td>23:55:45</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2021-04-22 23:56:03</td>\n",
       "      <td>23:56:03</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2021-04-21 22:00:00</td>\n",
       "      <td>22:00:00</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2021-04-21 18:27:00</td>\n",
       "      <td>18:27:00</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               time_id      Time  Day  Month  Year\n",
       "0  2021-04-23 15:02:47  15:02:47   23      4  2021\n",
       "4  2021-04-23 15:02:46  15:02:46   23      4  2021\n",
       "6  2021-04-23 15:02:45  15:02:45   23      4  2021\n",
       "8  2021-04-23 15:02:44  15:02:44   23      4  2021\n",
       "9  2021-04-23 15:02:43  15:02:43   23      4  2021\n",
       "..                 ...       ...  ...    ...   ...\n",
       "14 2021-04-22 14:18:31  14:18:31   22      4  2021\n",
       "15 2021-04-22 23:55:45  23:55:45   22      4  2021\n",
       "16 2021-04-22 23:56:03  23:56:03   22      4  2021\n",
       "18 2021-04-21 22:00:00  22:00:00   21      4  2021\n",
       "19 2021-04-21 18:27:00  18:27:00   21      4  2021\n",
       "\n",
       "[293 rows x 5 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_time_dim(fact_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#newspapers= Daily Mail, Extra, Variety, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Using cached PyMySQL-1.0.2-py3-none-any.whl (43 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.0.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql\n",
    "import pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pymysql.connections.Connection object at 0x7fa39385ac70>\n"
     ]
    }
   ],
   "source": [
    "connection = pymysql.connect(host= '127.0.0.1',\n",
    "                            user = 'root', \n",
    "                            password = '',\n",
    "                            db= '',\n",
    "                            cursorclass = pymysql.cursors.DictCursor)\n",
    "\n",
    "print (connection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "\n",
    "engine = create_engine('sqlite://', echo=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame({'name' : ['User 1', 'User 2', 'User 3'], 'age': [23,45,34]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'User 1', 23), (1, 'User 2', 45), (2, 'User 3', 34)]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df2.to_sql('test', con=engine)\n",
    "\n",
    "engine.execute(\"SELECT * FROM test\").fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sqlQuery = \"CREATE TABLE tweets (retweet_count INT, text VARCHAR (1000), author VARCHAR (255), created_at datetime)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor= connection.cursor()\n",
    "connection.commit()\n",
    "sql2 = \"show tables;\" \n",
    "result = cursor.fetchone()\n",
    "\n",
    "cols = \"`,`\".join([str(i) for i in df5.columns.tolist()])\n",
    "\n",
    "# Insert DataFrame recrds one by one.\n",
    "for i,row in df5.iterrows():\n",
    "    sqlQuery = \"INSERT INTO `tweets` (`\" +cols + \"`) VALUES (\" + \"%s,\"*(len(row)-1) + \"%s)\"\n",
    "    cursor.execute(sqlQuery, tuple(row))\n",
    "\n",
    "    # the connection is not autocommitted by default, so we must commit to save our changes\n",
    "    connection.commit()\n",
    "    \n",
    "sql = \"SELECT * FROM `tweets`\"\n",
    "cursor.execute(sql)\n",
    "\n",
    "result = cursor.fetchall()\n",
    "for i in result:\n",
    "    print(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
